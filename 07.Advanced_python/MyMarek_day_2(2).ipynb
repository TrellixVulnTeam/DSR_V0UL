{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our own 1-layer NNet + TensorFlow\n",
    "\n",
    "(Marco will elaborate on this in the future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/falkvandermeirsch/Documents/DSR/env/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.7\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import os, os.path, gzip, tempfile, urllib.request\n",
    "\n",
    "def load_mnist(kind='train', dataset='zalando'): # 'train' or 't10k'\n",
    "    \"\"\"based on https://github.com/zalandoresearch/fashion-mnist/blob/master/utils/mnist_reader.py\"\"\"\n",
    "\n",
    "    if dataset=='zalando':\n",
    "        url_base = 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/'\n",
    "    else:\n",
    "        url_base = 'http://yann.lecun.com/exdb/mnist/'\n",
    "\n",
    "    url_labels = url_base+'%s-labels-idx1-ubyte.gz'%kind\n",
    "    url_images = url_base+'%s-images-idx3-ubyte.gz'%kind\n",
    "\n",
    "    file_labels = os.path.join(tempfile.gettempdir(), '%s-labels-idx1-ubyte.gz'%kind)\n",
    "    file_images = os.path.join(tempfile.gettempdir(), '%s-images-idx3-ubyte.gz'%kind)\n",
    "\n",
    "    if not os.path.exists(file_labels):\n",
    "        urllib.request.urlretrieve(url_labels, file_labels)\n",
    "\n",
    "    if not os.path.exists(file_images):\n",
    "        urllib.request.urlretrieve(url_images, file_images)\n",
    "\n",
    "    with gzip.open(file_labels, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(file_images, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    assert len(images.shape)==2\n",
    "    assert len(labels.shape)==1\n",
    "    assert images.shape[0] == labels.shape[0]\n",
    "    assert images.shape[1] == 28*28\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {\n",
    " 0: 'T-shirt/top',\n",
    " 1: 'Trouser',\n",
    " 2: 'Pullover',\n",
    " 3: 'Dress',\n",
    " 4: 'Coat',\n",
    " 5: 'Sandal',\n",
    " 6: 'Shirt',\n",
    " 7: 'Sneaker',\n",
    " 8: 'Bag',\n",
    " 9: 'Ankle boot'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = load_mnist('train')\n",
    "X_test, Y_test = load_mnist('t10k')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each row represents an image of 28*28 = 784 px\n",
    "# X_train[0,:].reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,  44., 210., 255.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(X_train[0,:].reshape(28,28), [0, 25, 50, 75, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale brightness from {0..255} -> [0, 1]\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0,:].reshape(28,28), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ankle boot'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict[Y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 ways to do one-hot-encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode1(Y):\n",
    "    Y_enc = np.zeros((Y.shape[0], 10))\n",
    "    for row, index in zip(Y_enc, Y):\n",
    "        row[index] = 1\n",
    "    return Y_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode2(Y):\n",
    "    Y_enc = np.zeros((Y.shape[0], 10))\n",
    "    Y_enc[np.arange(Y.shape[0]), Y] = 1\n",
    "    return Y_enc  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode3(Y):\n",
    "    k = np.max(Y)+1\n",
    "    return np.eye(k)[Y,:] \n",
    "# np.eye is the I-matrix of size k, we take the columns found in the Y vector to create the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_decode(Y_enc):\n",
    "    return np.argmax(Y_enc, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-nearest neighbour classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.neighbors\n",
    "knn = sklearn.neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train, Y_train)\n",
    "X_test_subset = X_test[:100,]\n",
    "Y_test_subset = Y_test[:100,]\n",
    "\n",
    "Y_pred = knn.predict(X_test_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 5, 3, 4, 1, 2, 2, 8, 0, 2, 7,\n",
       "       7, 9, 1, 2, 6, 0, 9, 3, 8, 8, 3, 3, 8, 6, 7, 5, 7, 9, 0, 1, 6, 9,\n",
       "       6, 7, 2, 1, 2, 6, 4, 2, 5, 8, 2, 2, 8, 4, 8, 0, 7, 7, 8, 5, 1, 1,\n",
       "       6, 4, 7, 8, 7, 0, 2, 6, 2, 3, 1, 2, 8, 4, 1, 8, 5, 9, 5, 0, 3, 2,\n",
       "       0, 2, 5, 3, 6, 7, 1, 8, 0, 1, 2, 2], dtype=uint8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, 1, 6, 1, 4, 6, 5, 7, 4, 5, 7, 3, 4, 1, 2, 4, 8, 0, 2, 5,\n",
       "       7, 9, 1, 4, 6, 0, 9, 3, 8, 8, 3, 3, 8, 0, 7, 5, 7, 9, 6, 1, 3, 7,\n",
       "       6, 7, 2, 1, 2, 2, 4, 4, 5, 8, 2, 2, 8, 4, 8, 0, 7, 7, 8, 5, 1, 1,\n",
       "       2, 3, 9, 8, 7, 0, 2, 6, 2, 3, 1, 2, 8, 4, 1, 8, 5, 9, 5, 0, 3, 2,\n",
       "       0, 6, 5, 3, 6, 7, 1, 8, 0, 1, 4, 2], dtype=uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(Y_pred == Y_test_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "sklearn.metrics.accuracy_score(Y_pred, Y_test_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88         8\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       0.86      0.71      0.77        17\n",
      "           3       0.78      1.00      0.88         7\n",
      "           4       0.60      0.86      0.71         7\n",
      "           5       0.89      0.89      0.89         9\n",
      "           6       0.75      0.60      0.67        10\n",
      "           7       0.82      0.82      0.82        11\n",
      "           8       1.00      1.00      1.00        12\n",
      "           9       0.83      0.83      0.83         6\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       100\n",
      "   macro avg       0.84      0.86      0.84       100\n",
      "weighted avg       0.86      0.85      0.85       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sklearn.metrics.classification_report(Y_pred, Y_test_subset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's now implement it ourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's take a smaller subset to minimize computing time\n",
    "X_train_subset = X_test[:6000,]\n",
    "Y_train_subset = Y_test[:6000,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my solution\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def knn(X_train, Y_train, X_test, n_neighbors):\n",
    "    \n",
    "    # for each digit in X_test\n",
    "    #    compute distance to all digits in X_train\n",
    "    #    choose the index of n_neighbors smallest distances\n",
    "    #    choose the corresponding elements in Y_train\n",
    "    #    compute the mode of these elements\n",
    "    #    output the mode to Y_pred\n",
    "    Y_pred = np.empty(X_test.shape[0], dtype=Y_train.dtype)\n",
    "    for i, new_point in enumerate(X_test):\n",
    "        dst = np.zeros(X_train.shape[0])\n",
    "        for j, point in enumerate(X_train):\n",
    "            dst[j] = distance.euclidean(new_point, point)\n",
    "        nearest_points = np.argsort(dst)[:n_neighbors]\n",
    "        (values,counts) = np.unique(Y_train[nearest_points],return_counts=True)\n",
    "        ind=np.argmax(counts)\n",
    "        Y_pred[i] = values[ind]\n",
    "    \n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.6 s ± 232 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%timeit Y_pred = knn(X_train_subset, Y_train_subset, X_test_subset, 3)\n",
    "np.mean(Y_pred == Y_test_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode(Y):\n",
    "    vals, cnts = np.unique(Y, return_counts=True)\n",
    "    return np.random.choice(vals[cnts==cnts.max()], 1)\n",
    "\n",
    "def knn(X_train, Y_train, X_test, n_neighbors):  \n",
    "    # for each digit in X_test\n",
    "    #    compute distance to all digits in X_train\n",
    "    #    choose the index of n_neighbors smallest distances\n",
    "    #    choose the corresponding elements in Y_train\n",
    "    #    compute the mode of these elements\n",
    "    #    output the mode to Y_pred\n",
    "    Y_pred = np.empty(X_test.shape[0], dtype=Y_train.dtype)\n",
    "    n_samples = X_test.shape[0]\n",
    "    for i in range(n_samples):\n",
    "        d = np.sqrt(np.sum((X_test[i,:] - X_train)**2, axis=1))\n",
    "        assert d.shape[0] == X_train.shape[0]\n",
    "        indexes_neighbors = np.argsort(d)[:n_neighbors]\n",
    "        Y_pred[i] = mode(Y_train[indexes_neighbors])\n",
    "    \n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.04 s ± 63.3 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%timeit Y_pred = knn(X_train_subset, Y_train_subset, X_test_subset, 3)\n",
    "np.mean(Y_pred == Y_test_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multinomial logistic regression a.k.a. 1-Layer nnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(r):\n",
    "    r2 = np.exp(r)\n",
    "    return r2 / np.sum(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10650698, 0.10650698, 0.78698604])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = np.r_[0, 0, 2]\n",
    "softmax(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.random.randn(785, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.009, 0.   , 0.99 , 0.   , 0.   , 0.   , 0.001, 0.   ,\n",
       "        0.   ]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(softmax(np.r_[1.0, X_test[0,:]].reshape(1,-1) @ C), 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This exercise was taken from PaweÅ‚ Jankiewicz and partially modified\n",
    "https://github.com/logicai-io/pipelines-sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/categories.csv').loc[lambda x: x.short_description.str.len() > 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>website</th>\n",
       "      <th>categories</th>\n",
       "      <th>short_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://iFans.com</td>\n",
       "      <td>['News']</td>\n",
       "      <td>iFans is a community-based forum and portal th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.braingig.com</td>\n",
       "      <td>['Non Profit', 'Finance']</td>\n",
       "      <td>Connecting grant funders and seekers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.twinelabs.com/</td>\n",
       "      <td>[]</td>\n",
       "      <td>Twine is a powerful platform for internal mobi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.SumaGreen.com</td>\n",
       "      <td>['Biotechnology']</td>\n",
       "      <td>SumaGreen is an agro firm committed to enablin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://worldstartupreport.strikingly.com/</td>\n",
       "      <td>['Market Research', 'CleanTech', 'Clean Energy']</td>\n",
       "      <td>World Startup Report is a social mission to do...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     website  \\\n",
       "0                           http://iFans.com   \n",
       "1                    http://www.braingig.com   \n",
       "2                 https://www.twinelabs.com/   \n",
       "3                   http://www.SumaGreen.com   \n",
       "4  http://worldstartupreport.strikingly.com/   \n",
       "\n",
       "                                         categories  \\\n",
       "0                                          ['News']   \n",
       "1                         ['Non Profit', 'Finance']   \n",
       "2                                                []   \n",
       "3                                 ['Biotechnology']   \n",
       "4  ['Market Research', 'CleanTech', 'Clean Energy']   \n",
       "\n",
       "                                   short_description  \n",
       "0  iFans is a community-based forum and portal th...  \n",
       "1              Connecting grant funders and seekers.  \n",
       "2  Twine is a powerful platform for internal mobi...  \n",
       "3  SumaGreen is an agro firm committed to enablin...  \n",
       "4  World Startup Report is a social mission to do...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "website              object\n",
       "categories           object\n",
       "short_description    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def cut_array(l):\n",
    "    l_ = ast.literal_eval(l)\n",
    "    if len(l_)>2:\n",
    "        return l_[0:1]\n",
    "    else:\n",
    "        return l_\n",
    "\n",
    "df['categories_list'] = df['categories'].apply(lambda x: cut_array(x))\n",
    "df = df[df.categories != '[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                            ['News']\n",
       "1                           ['Non Profit', 'Finance']\n",
       "3                                   ['Biotechnology']\n",
       "4    ['Market Research', 'CleanTech', 'Clean Energy']\n",
       "5                          ['Accounting', 'Software']\n",
       "Name: categories, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['categories'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "categories\n",
       "[\"Men's\", \"Women's\", 'Beauty', 'Fashion']       1\n",
       "[\"Men's\", \"Women's\", 'Beauty']                  1\n",
       "[\"Men's\", \"Women's\", 'Children', 'Textiles']    1\n",
       "[\"Men's\", \"Women's\", 'Events']                  1\n",
       "[\"Men's\", \"Women's\", 'Fashion']                 7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('categories').size().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.short_description.values\n",
    "y = df.categories_list.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is to predict not one but multiple categories for each observation. \n",
    "One of the solutions is to create a binary classifier for each unique category.\n",
    "It is fairly simple to do using scikit-learn but we need to create our own classifier.\n",
    "\n",
    "Task:\n",
    "\n",
    "1. Write a custom classifier to solve this.\n",
    "2. Evaluate its results (what measure could be good for comparing sets?)\n",
    "\n",
    "\n",
    "Hints:\n",
    "\n",
    "You can keep your classifiers in a dictionary `class name -> Classifier`\n",
    "Both in fit and predict you need to iterate over all unique classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # get all rows where the short description is big enough\n",
    "    df = pd.read_csv('../data/categories.csv').loc[lambda x: x.short_description.str.len() > 10]\n",
    "    \n",
    "    # convert the categories list from string to list\n",
    "    df['categories_list'] = df['categories'].apply(lambda x: cut_array(x))\n",
    "    \n",
    "    # remove the rows without categories\n",
    "    df = df[df.categories != '[]']\n",
    "    \n",
    "    #print(df.head())\n",
    "    return df.short_description.values, df.categories_list.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "# make the classifier\n",
    "class OneVsRestClassifier(BaseEstimator, ClassifierMixin):\n",
    "    \n",
    "    def __init__(self, base_estimator):\n",
    "        self.base_estimator = base_estimator\n",
    "        self.estimators = {}\n",
    "\n",
    "    def fit(self, X, y=None, sample_weight=None):\n",
    "        # get all the unique categories\n",
    "        self.classes = np.unique([item for sub in y for item in sub])\n",
    "        \n",
    "        print(\"Fitting\")\n",
    "        \n",
    "        # for each category\n",
    "        for cl in self.classes:\n",
    "            # clone base estimator to remove previous configurations\n",
    "            est_ = clone(self.base_estimator) \n",
    "            # fit the data to a vector with 0's and 1's according to if the category is present for the sample\n",
    "            est_.fit(X, self._isin(y, cl)) \n",
    "            # save this estimator in the list of estimators\n",
    "            self.estimators[cl] = est_\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        print(\"Predicting\")\n",
    "        # make an empty predicted category list for each sample\n",
    "        outputs = [[] for _ in range(X.shape[0])]\n",
    "        \n",
    "        # for each category\n",
    "        for cl in self.classes:\n",
    "            # get the indices for the samples where the category is predicted\n",
    "            true_indices = np.where(self.estimators[cl].predict(X) == 1)[0]\n",
    "            \n",
    "            # for each sample with this predicted category add the category name to the output vector\n",
    "            for i in true_indices:\n",
    "                outputs[i].append(cl)\n",
    "        return outputs\n",
    "    \n",
    "    def _isin(self, ys, cl):\n",
    "        # create the vector with 0's and 1's according to if the category is present for the sample\n",
    "        return np.array([cl in y for y in ys], dtype=np.int)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the f1 score\n",
    "def f1(true, pred):\n",
    "    #print(f'true: {true} - pred: {pred}')\n",
    "    if len(pred) == 0:\n",
    "        return 0\n",
    "    tp = len(set(true).intersection(set(pred)))\n",
    "    precision = tp / len(pred)\n",
    "    recall = tp / len(true)\n",
    "    if (precision + recall) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        #print(f'f: {2 * precision * recall / (precision + recall)}')\n",
    "        return (2 * precision * recall / (precision + recall))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a CountVectorizer function and save in a pipeline\n",
    "def model_definition_words(min_df) -> Pipeline:\n",
    "    est = make_pipeline(\n",
    "        CountVectorizer(min_df=min_df, binary=True, analyzer='word', stop_words='english'),\n",
    "        OneVsRestClassifier(base_estimator=AdaBoostClassifier())\n",
    "    )\n",
    "    return est\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def validate_model_multiple_outputs(min_df):\n",
    "    print('Loading data')\n",
    "    X, y = load_data()\n",
    "    \n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X[:10000], y[:10000], random_state=1)\n",
    "    \n",
    "    # show the first lines of the test data\n",
    "    #print('test data:')\n",
    "    #print(pd.DataFrame(np.transpose(np.vstack((X_te[:5], y_te[:5])))))\n",
    "    \n",
    "    est = model_definition_words(min_df)\n",
    "    \n",
    "    est.fit(X_tr, y_tr)\n",
    "    \n",
    "    preds = est.predict(X_te)\n",
    "    \n",
    "    mean_f1 = np.array([f1(true, pred) for true, pred in zip(y_te, preds)]).mean()\n",
    "    print(\"Multiple Labels F1\", mean_f1)\n",
    "    return X_tr, X_te, y_tr, y_te, preds\n",
    "    \n",
    "#X_tr, X_te, y_tr, y_te, preds = validate_model_multiple_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "min_df = 6\n",
      "Loading data\n",
      "Fitting\n",
      "Predicting\n",
      "Multiple Labels F1 0.08905333333333333\n",
      "-----------------\n",
      "min_df = 7\n",
      "Loading data\n",
      "Fitting\n",
      "Predicting\n",
      "Multiple Labels F1 0.08650666666666666\n",
      "-----------------\n",
      "min_df = 8\n",
      "Loading data\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b2ea52ecff5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-----------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'min_df = {i}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_model_multiple_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-14985e1c0d43>\u001b[0m in \u001b[0;36mvalidate_model_multiple_outputs\u001b[0;34m(min_df)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvalidate_model_multiple_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loading data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_te\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_te\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-60072b39bc35>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# convert the categories list from string to list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'categories_list'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'categories'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcut_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# remove the rows without categories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/DSR/env/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   3192\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3193\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3194\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3196\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/inference.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-60072b39bc35>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# convert the categories list from string to list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'categories_list'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'categories'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcut_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# remove the rows without categories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-e202d4cf447b>\u001b[0m in \u001b[0;36mcut_array\u001b[0;34m(l)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcut_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0ml_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ml_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ast.py\u001b[0m in \u001b[0;36mliteral_eval\u001b[0;34m(node_or_string)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \"\"\"\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_or_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mnode_or_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_or_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_or_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExpression\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mnode_or_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode_or_string\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/ast.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(source, filename, mode)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mEquivalent\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPyCF_ONLY_AST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \"\"\"\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPyCF_ONLY_AST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(6, 9, 1):\n",
    "    print('-----------------')\n",
    "    print(f'min_df = {i}')\n",
    "    X_tr, X_te, y_tr, y_te, preds = validate_model_multiple_outputs(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(X_te))\n",
    "print(len(y_te))\n",
    "print(len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ = []\n",
    "for row in preds:\n",
    "    cats = \"[\"\n",
    "    for i, cat in enumerate(row):\n",
    "        if i != 0:\n",
    "            cats += \", \"\n",
    "        cats += \"'\" + cat + \"'\"\n",
    "    cats += \"]\"\n",
    "    preds_.append(cats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview = np.transpose(np.vstack((X_te, y_te, preds)))\n",
    "pd.DataFrame(overview, columns=['description', 'truth', 'predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution1**\n",
    "<div>\n",
    "def load_data():\n",
    "    df = pd.read_csv('data/categories.csv').loc[lambda x: x.short_description.str.len() > 10]\n",
    "    df['categories_list'] = df['categories'].apply(lambda x: cut_array(x))\n",
    "    df = df[df.categories != '[]']\n",
    "    print(df.head())\n",
    "    return df.short_description.values, df.categories_list.values\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "\n",
    "class OneVsRestClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_estimator):\n",
    "        self.base_estimator = base_estimator\n",
    "        self.estimators = {}\n",
    "\n",
    "    def fit(self, X, y=None, sample_weight=None):\n",
    "        self.classes = np.unique([item for sub in y for item in sub])\n",
    "        print(\"Fitting\")\n",
    "        for cl in self.classes:\n",
    "            est_ = clone(self.base_estimator)\n",
    "            est_.fit(X, self._isin(y, cl))\n",
    "            self.estimators[cl] = est_\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        print(\"Predicting\")\n",
    "        outputs = [[] for _ in range(X.shape[0])]\n",
    "        for cl in self.classes:\n",
    "            true_indices = np.where(self.estimators[cl].predict(X) == 1)[0]\n",
    "            for i in true_indices:\n",
    "                outputs[i].append(cl)\n",
    "        return outputs\n",
    "    \n",
    "    def _isin(self, ys, cl):\n",
    "        return np.array([cl in y for y in ys], dtype=np.int)\n",
    "    \n",
    "    \n",
    "def f1(true, pred):\n",
    "    if len(pred) == 0:\n",
    "        return 0\n",
    "    tp = len(set(true).intersection(set(pred)))\n",
    "    precision = tp / len(pred)\n",
    "    recall = tp / len(true)\n",
    "    if (precision + recall) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (2 * precision * recall / (precision + recall))\n",
    "    \n",
    "    \n",
    "def model_definition_words() -> Pipeline:\n",
    "    est = make_pipeline(\n",
    "        CountVectorizer(min_df=5, binary=True, analyzer='word'),\n",
    "        OneVsRestClassifier(base_estimator=RandomForestClassifier())\n",
    "    )\n",
    "    return est\n",
    "\n",
    "\n",
    "def validate_model_multiple_outputs():\n",
    "    print('Loading data')\n",
    "    X, y = load_data()\n",
    "    \n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X[:10000], y[:10000], random_state=1)\n",
    "    est = model_definition_words()\n",
    "    est.fit(X_tr, y_tr)\n",
    "    mean_f1 = np.array([f1(true, pred) for true, pred in zip(y_te, preds)]).mean()\n",
    "    print(\"Multiple Labels F1\", mean_f1)\n",
    "    \n",
    "validate_model_multiple_outputs()\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution 2**\n",
    "<div>\n",
    "\n",
    "def load_data():\n",
    "    df = pd.read_csv('data/categories.csv').loc[lambda x: x.short_description.str.len() > 10]\n",
    "    print(df.head())\n",
    "    return df.short_description.values, df.categories.values\n",
    "\n",
    "\n",
    "class OneVsRestClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_estimator):\n",
    "        self.base_estimator = base_estimator\n",
    "        self.estimators = {}\n",
    "\n",
    "    def fit(self, X, y=None, sample_weight=None):\n",
    "        self.classes = list(set(chain(*y)))\n",
    "        print(\"Fitting\")\n",
    "        for cl in self.classes:\n",
    "            est_ = clone(self.base_estimator)\n",
    "            est_.fit(X, self._isin(y, cl))\n",
    "            self.estimators[cl] = est_\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        print(\"Predicting\")\n",
    "        outputs = [[] for _ in range(X.shape[0])]\n",
    "        for cl in self.classes:\n",
    "            true_indices = np.where(self.estimators[cl].predict(X) == 1)[0]\n",
    "            for i in true_indices:\n",
    "                outputs[i].append(cl)\n",
    "        return outputs\n",
    "\n",
    "    def _isin(self, ys, cl):\n",
    "        return np.array([cl in y for y in ys], dtype=np.int)\n",
    "    \n",
    "    \n",
    "def f1(true, pred):\n",
    "    if len(pred) == 0:\n",
    "        return 0\n",
    "    tp = len(set(true).intersection(set(pred)))\n",
    "    precision = tp / len(pred)\n",
    "    recall = tp / len(true)\n",
    "    if (precision + recall) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (2 * precision * recall / (precision + recall))\n",
    "    \n",
    "    \n",
    "def model_definition_words() -> Pipeline:\n",
    "    est = make_pipeline(\n",
    "        CountVectorizer(min_df=5, binary=True, analyzer='word'),\n",
    "        OneVsRestClassifier(base_estimator=RandomForestClassifier(n_estimators=100, min_samples_leaf=10, min_samples_split=20,\n",
    "                                                        n_jobs=-2))\n",
    "    )\n",
    "    return est\n",
    "\n",
    "\n",
    "def validate_model_multiple_outputs():\n",
    "    print('Loading data')\n",
    "    X, y = load_data()\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X[:10000], y[:10000], random_state=1)\n",
    "    est = model_definition_words()\n",
    "    est.fit(X_tr, y_tr)\n",
    "    preds = est.predict(X_te)\n",
    "    mean_f1 = np.array([f1(true, pred) for true, pred in zip(y_te, preds)]).mean()\n",
    "    print(\"Multiple Labels F1\", mean_f1)\n",
    "    \n",
    "validate_model_multiple_outputs()\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NNets with NumPy and Tensorflow (cont'd)\n",
    "# Hardcore Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sklearn.metrics\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, os.path, gzip, tempfile, urllib.request\n",
    "\n",
    "def load_mnist(kind='train', dataset='zalando'): # 'train' or 't10k'\n",
    "    \"\"\"based on https://github.com/zalandoresearch/fashion-mnist/blob/master/utils/mnist_reader.py\"\"\"\n",
    "    \n",
    "    if dataset=='zalando':\n",
    "        url_base = 'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/'\n",
    "    else:\n",
    "        url_base = 'http://yann.lecun.com/exdb/mnist/'\n",
    "        \n",
    "    url_labels = url_base+'%s-labels-idx1-ubyte.gz'%kind\n",
    "    url_images = url_base+'%s-images-idx3-ubyte.gz'%kind\n",
    "\n",
    "    file_labels = os.path.join(tempfile.gettempdir(), '%s-labels-idx1-ubyte.gz'%kind)\n",
    "    file_images = os.path.join(tempfile.gettempdir(), '%s-images-idx3-ubyte.gz'%kind)\n",
    "    \n",
    "    if not os.path.exists(file_labels):\n",
    "        urllib.request.urlretrieve(url_labels, file_labels)\n",
    "        \n",
    "    if not os.path.exists(file_images):\n",
    "        urllib.request.urlretrieve(url_images, file_images)\n",
    "    \n",
    "    with gzip.open(file_labels, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,\n",
    "                               offset=8)\n",
    "\n",
    "    with gzip.open(file_images, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,\n",
    "                               offset=16).reshape(len(labels), 784)\n",
    "\n",
    "    assert len(images.shape)==2\n",
    "    assert len(labels.shape)==1\n",
    "    assert images.shape[0] == labels.shape[0]\n",
    "    assert images.shape[1] == 28*28\n",
    "    return images, labels\n",
    "\n",
    "X_train, Y_train = load_mnist('train')\n",
    "X_test,  Y_test  = load_mnist('t10k')\n",
    "\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "def one_hot_encode(Y):\n",
    "    k = np.max(Y)+1\n",
    "    return np.eye(k)[Y,:]\n",
    "\n",
    "Y_train2 = one_hot_encode(Y_train)\n",
    "Y_test2  = one_hot_encode(Y_test)\n",
    "\n",
    "def one_hot_decode(Y2):\n",
    "    return np.argmax(Y2, axis=1)\n",
    "\n",
    "def mode(Y):\n",
    "    vals, cnts = np.unique(Y, return_counts=True)\n",
    "    return np.random.choice(vals[cnts==cnts.max()], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = np.insert(X_train, 0, 1, axis=1)\n",
    "X_test2  = np.insert(X_test , 0, 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(r):  # softmax for r -- a vector\n",
    "    r2 = np.exp(r)\n",
    "    return r2/np.sum(r2,axis=1).reshape(-1,1)\n",
    "\n",
    "# rewrite the above so that you can compute softmax for each row in matrix r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "C = np.random.randn(785, 10)\n",
    "Y_pred = softmax(X_train2 @ C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.03, 0.89, 0.  , 0.  , 0.08, 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.07, 0.  , 0.  , 0.  , 0.78, 0.  , 0.  , 0.15, 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.85, 0.14, 0.  , 0.01, 0.  ],\n",
       "       [0.  , 0.05, 0.  , 0.  , 0.  , 0.95, 0.  , 0.  , 0.  , 0.  ]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(Y_pred[:5,:],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04795"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy\n",
    "def accuracy(Y_pred, Y_train):\n",
    "    return np.mean(one_hot_decode(Y_pred) == Y_train)\n",
    "\n",
    "accuracy(Y_pred, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
       " array([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000]))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(C, X_train2, Y_train2):\n",
    "    # Y_train2 - one-hot-encoded\n",
    "    Y_pred =  softmax(X_train2 @ C)\n",
    "    return -np.sum(Y_train2*np.log(Y_pred))/X_train2.shape[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.716710024471196 0.11415\n",
      "14.623067445282864 0.16771666666666665\n",
      "10.716627642887518 0.07833333333333334\n",
      "10.489890116429194 0.1546\n",
      "9.702626155724984 0.12291666666666666\n"
     ]
    }
   ],
   "source": [
    "best_C = None\n",
    "best_error = np.inf\n",
    "for i in range(1000):\n",
    "    C = np.random.randn(785, 10)\n",
    "    err = cross_entropy(C, X_train2, Y_train2)\n",
    "    if err < best_error:\n",
    "        best_error = err\n",
    "        best_C = C\n",
    "        print(best_error, accuracy(softmax(X_train2@C),Y_train))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_cross_entropy(C, X_train2, Y_train2):\n",
    "    Y_pred = softmax(X_train2 @ C)\n",
    "    return -X_train2.T @ (Y_train2 - Y_pred) / X_train2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   9: cross_entropy= 8.0049560, acc_train=0.106, acc_test=0.109\n",
      "  19: cross_entropy= 5.9949248, acc_train=0.199, acc_test=0.206\n",
      "  29: cross_entropy= 4.9223162, acc_train=0.280, acc_test=0.285\n",
      "  39: cross_entropy= 4.2912178, acc_train=0.337, acc_test=0.343\n",
      "  49: cross_entropy= 3.8827793, acc_train=0.380, acc_test=0.384\n",
      "  59: cross_entropy= 3.5953002, acc_train=0.413, acc_test=0.415\n",
      "  69: cross_entropy= 3.3792933, acc_train=0.438, acc_test=0.441\n",
      "  79: cross_entropy= 3.2084810, acc_train=0.456, acc_test=0.458\n",
      "  89: cross_entropy= 3.0680396, acc_train=0.474, acc_test=0.475\n",
      "  99: cross_entropy= 2.9491259, acc_train=0.488, acc_test=0.487\n"
     ]
    }
   ],
   "source": [
    "# Gradient Descent\n",
    "np.random.seed(123)\n",
    "C = np.random.randn(785, 10)\n",
    "eta = 0.1 # \"learning rate\"\n",
    "for i in range(100):\n",
    "    C = C-eta*grad_cross_entropy(C, X_train2, Y_train2)\n",
    "    \n",
    "    if i %10 == 9:\n",
    "        print(\"%4d: cross_entropy=%10.7f, acc_train=%.3f, acc_test=%.3f\"%(i, \n",
    "            cross_entropy(C, X_train2, Y_train2),\n",
    "            accuracy(softmax(X_train2 @ C), Y_train),\n",
    "            accuracy(softmax(X_test2 @ C), Y_test),\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   9: cross_entropy= 1.2649534, acc_train=0.713, acc_test=0.702\n",
      "  19: cross_entropy= 1.0132985, acc_train=0.757, acc_test=0.748\n",
      "  29: cross_entropy= 0.8956163, acc_train=0.777, acc_test=0.767\n",
      "  39: cross_entropy= 0.8199046, acc_train=0.789, acc_test=0.777\n",
      "  49: cross_entropy= 0.7656090, acc_train=0.797, acc_test=0.783\n",
      "  59: cross_entropy= 0.7270596, acc_train=0.803, acc_test=0.787\n",
      "  69: cross_entropy= 0.6935507, acc_train=0.809, acc_test=0.794\n",
      "  79: cross_entropy= 0.6654487, acc_train=0.813, acc_test=0.798\n",
      "  89: cross_entropy= 0.6437228, acc_train=0.817, acc_test=0.802\n",
      "  99: cross_entropy= 0.6220315, acc_train=0.820, acc_test=0.803\n"
     ]
    }
   ],
   "source": [
    "# Mini-batch/stochastic Gradient Descent\n",
    "np.random.seed(123)\n",
    "C = np.random.randn(785, 10)\n",
    "eta = 0.1 # \"learning rate\"\n",
    "batch_size = 600\n",
    "for i in range(100):\n",
    "    # subset = np.random.randint(0, X_train2.shape[0], batch_size)\n",
    "    for j in range(X_train2.shape[0]//batch_size):\n",
    "        subset = np.random.choice(np.arange(X_train2.shape[0]), batch_size, replace=False)\n",
    "        C = C-eta*grad_cross_entropy(C, X_train2[subset,:], Y_train2[subset,:])\n",
    "    \n",
    "    if i %10 == 9:\n",
    "        print(\"%4d: cross_entropy=%10.7f, acc_train=%.3f, acc_test=%.3f\"%(i, \n",
    "            cross_entropy(C, X_train2, Y_train2),\n",
    "            accuracy(softmax(X_train2 @ C), Y_train),\n",
    "            accuracy(softmax(X_test2 @ C), Y_test),\n",
    "            ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Intro\n",
    "\n",
    "in other words: we've learned a lot so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "x = tf.placeholder(tf.float64, [None, 785])\n",
    "y = tf.placeholder(tf.float64, [None, 10])\n",
    "C = tf.Variable(tf.random_normal([785, 10], dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder_4:0' shape=(?, 785) dtype=float64>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder_5:0' shape=(?, 10) dtype=float64>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable_1:0' shape=(785, 10) dtype=float64_ref>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Softmax:0' shape=(?, 10) dtype=float64>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = tf.nn.softmax( tf.matmul(x,C) )\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cross_entropy(C, X_train2, Y_train2):\n",
    "#     # Y_train2 - one-hot-encoded\n",
    "#     Y_pred =  softmax(X_train2 @ C)\n",
    "#     return -np.sum(Y_train2*np.log(Y_pred))/X_train2.shape[0]\n",
    "cross_entropy = -tf.reduce_sum(y*tf.log(y_pred))/tf.cast(tf.shape(x)[0], tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.mean(one_hot_decode(y_pred) == one_hot_decode(y_test2))\n",
    "accuracy = tf.reduce_mean(\n",
    "    tf.cast(tf.equal(tf.argmax(y_pred, 1), tf.argmax(y, 1)), tf.float64)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C = C-eta*grad_cross_entropy(C, X_train2, Y_train2)\n",
    "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   9: cross_entropy= 1.3601004\n",
      "  19: cross_entropy= 1.0728300\n",
      "  29: cross_entropy= 0.9284891\n",
      "  39: cross_entropy= 0.8422055\n",
      "  49: cross_entropy= 0.7865233\n",
      "  59: cross_entropy= 0.7414442\n",
      "  69: cross_entropy= 0.7040721\n",
      "  79: cross_entropy= 0.6770457\n",
      "  89: cross_entropy= 0.6529887\n",
      "  99: cross_entropy= 0.6327627\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size = 600\n",
    "for i in range(100):\n",
    "    # subset = np.random.randint(0, X_train2.shape[0], batch_size)\n",
    "    for j in range(X_train2.shape[0]//batch_size):\n",
    "        subset = np.random.choice(np.arange(X_train2.shape[0]), batch_size, replace=False)\n",
    "        #C = C-eta*grad_cross_entropy(C, X_train2[subset,:], Y_train2[subset,:])\n",
    "        sess.run(train_step, feed_dict={\n",
    "            x: X_train2[subset,:],\n",
    "            y: Y_train2[subset,:]\n",
    "        })\n",
    "    \n",
    "    if i %10 == 9:\n",
    "        print(\"%4d: cross_entropy=%10.7f\"%(i, \n",
    "            sess.run(cross_entropy, feed_dict={\n",
    "                x: X_train2,\n",
    "                y: Y_train2\n",
    "            })\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.0913 - acc: 0.6581\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.7360 - acc: 0.7647\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.6563 - acc: 0.7905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f64166c6630>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(10, input_dim=785)) # X -> C=np.random.randn(785,10); X@C ->  Y_1\n",
    "model.add(Activation(\"softmax\")) # Y_1 -> softmax -> Y_2\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train2, Y_train2, batch_size=100, epochs=3, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.5173 - acc: 0.8195\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.3868 - acc: 0.8614\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.3553 - acc: 0.8729\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.3286 - acc: 0.8810\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.3219 - acc: 0.8830\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.3044 - acc: 0.8886\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.2981 - acc: 0.8914\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2972 - acc: 0.8931\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2869 - acc: 0.8959\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2729 - acc: 0.8986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6414c0ab38>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(28*4, input_dim=785)) \n",
    "model.add(Activation(\"exponential\"))\n",
    "model.add(Dense(28, input_dim=25)) \n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dense(10, input_dim=25)) \n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train2, Y_train2, batch_size=60, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8745"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.argmax(model.predict(X_test2),axis=1) == Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

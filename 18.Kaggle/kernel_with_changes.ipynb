{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/train.csv\")\n",
    "data[\"is_test\"] = 0\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "test[\"is_test\"] = 1\n",
    "data = data.append(test, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by=[\"year\", \"month\", \"day\", \"sched_dep_time\"], inplace=True)\n",
    "data[\"date\"] = data.apply(lambda x: str(x[\"year\"]) + \"_\" + str(x[\"month\"]) + \"_\" + str(x[\"day\"]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"sched_arr_hr\"] = data[\"sched_arr_time\"].apply(lambda x: int(x / 100))\n",
    "\n",
    "data[\"sched_dep_hr\"] = data[\"sched_dep_time\"].apply(lambda x: int(x / 100))\n",
    "\n",
    "weather = pd.read_csv(\"data/weather.csv\")\n",
    "weather.drop_duplicates(subset=[\"year\", \"month\", \"day\"], keep=\"first\", inplace=True)\n",
    "weather[\"date\"] = weather.apply(lambda x: str(x[\"year\"]) + \"_\" + str(x[\"month\"]) + \"_\" + str(x[\"day\"]), axis=1)\n",
    "weather.drop([\"year\", \"month\", \"day\", \"hour\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(weather, on=[\"origin\", \"date\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"precip\"].fillna(\"NA\", inplace=True)\n",
    "data[\"precip\"] = data[\"precip\"].apply(lambda x: -999 if str(x) == \"NA\" else x)\n",
    "data[\"temp\"].fillna(\"NA\", inplace=True)\n",
    "data[\"temp\"] = data[\"temp\"].apply(lambda x: -999 if str(x) == \"NA\" else x)\n",
    "data[\"humid\"].fillna(\"NA\", inplace=True)\n",
    "data[\"humid\"] = data[\"humid\"].apply(lambda x: -999 if str(x) == \"NA\" else x)\n",
    "data[\"wind_speed\"].fillna(\"NA\", inplace=True)\n",
    "data[\"wind_speed\"] = data[\"wind_speed\"].apply(lambda x: -999 if str(x) == \"NA\" else x)\n",
    "data[\"wind_gust\"].fillna(\"NA\", inplace=True)\n",
    "data[\"wind_gust\"] = data[\"wind_gust\"].apply(lambda x: -999 if str(x) == \"NA\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "336776"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(date_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series1 = []\n",
    "time_series2 = []\n",
    "time_series3 = []\n",
    "for i in range(len(data)):\n",
    "    time_series1.append(i // 3)\n",
    "    time_series1.append((i +1) // 3)\n",
    "    time_series1.append((i +2) // 3)\n",
    "data['time_feature1'] = time_series\n",
    "data['time_feature2'] = time_series\n",
    "data['time_feature3'] = time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_dict = {}\n",
    "delay_dict_month = {}\n",
    "delay_dict_tf1 = {}\n",
    "delay_dict_tf2 = {}\n",
    "delay_dict_tf3 = {}\n",
    "\n",
    "origin_vals = data[\"origin\"].values\n",
    "date_vals = data[\"date\"].values\n",
    "\n",
    "month_vals = data[\"month\"].values\n",
    "tf_vals1 = data[\"time_feature1\"].values\n",
    "tf_vals2 = data[\"time_feature2\"].values\n",
    "tf_vals3 = data[\"time_feature3\"].values\n",
    "\n",
    "delay_vals = data[\"is_delayed\"].values\n",
    "is_test = data[\"is_test\"].values\n",
    "for n in range(0, len(data)):\n",
    "    if origin_vals[n] not in delay_dict:\n",
    "        delay_dict[origin_vals[n]] = {}\n",
    "        delay_dict_month[origin_vals[n]] = {}\n",
    "        delay_dict_tf1[origin_vals[n]] = {}\n",
    "        delay_dict_tf2[origin_vals[n]] = {}\n",
    "        delay_dict_tf3[origin_vals[n]] = {}\n",
    "        \n",
    "    if date_vals[n] not in delay_dict[origin_vals[n]]:\n",
    "        delay_dict[origin_vals[n]][date_vals[n]] = {\"total\":0, \"train\":[]}\n",
    "    \n",
    "    if month_vals[n] not in delay_dict_month[origin_vals[n]]:\n",
    "        delay_dict_month[origin_vals[n]][month_vals[n]] = {\"total\":0, \"train\":[]}\n",
    "    \n",
    "    if tf_vals1[n] not in delay_dict_tf1[origin_vals[n]]:\n",
    "        delay_dict_tf1[origin_vals[n]][tf_vals1[n]] = {\"total\":0, \"train\":[]}\n",
    "    \n",
    "    if tf_vals2[n] not in delay_dict_tf2[origin_vals[n]]:\n",
    "        delay_dict_tf2[origin_vals[n]][tf_vals2[n]] = {\"total\":0, \"train\":[]}\n",
    "    \n",
    "    if tf_vals3[n] not in delay_dict_tf3[origin_vals[n]]:\n",
    "        delay_dict_tf3[origin_vals[n]][tf_vals3[n]] = {\"total\":0, \"train\":[]}\n",
    "        \n",
    "    if is_test[n] == 0:\n",
    "        delay_dict[origin_vals[n]][date_vals[n]][\"train\"].append(delay_vals[n])\n",
    "        \n",
    "        delay_dict_month[origin_vals[n]][month_vals[n]][\"train\"].append(delay_vals[n])\n",
    "        delay_dict_tf1[origin_vals[n]][tf_vals1[n]][\"train\"].append(delay_vals[n])\n",
    "        delay_dict_tf2[origin_vals[n]][tf_vals2[n]][\"train\"].append(delay_vals[n])\n",
    "        delay_dict_tf3[origin_vals[n]][tf_vals3[n]][\"train\"].append(delay_vals[n])\n",
    "        \n",
    "    delay_dict[origin_vals[n]][date_vals[n]][\"total\"] += 1\n",
    "    \n",
    "    delay_dict_month[origin_vals[n]][month_vals[n]][\"total\"] += 1\n",
    "    delay_dict_tf1[origin_vals[n]][tf_vals1[n]][\"total\"] += 1\n",
    "    delay_dict_tf2[origin_vals[n]][tf_vals2[n]][\"total\"] += 1\n",
    "    delay_dict_tf3[origin_vals[n]][tf_vals3[n]][\"total\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_day = np.zeros(len(data))\n",
    "delay_day = np.zeros(len(data))\n",
    "delay_month = np.zeros(len(data))\n",
    "delay_tf1 = np.zeros(len(data))\n",
    "delay_tf2 = np.zeros(len(data))\n",
    "delay_tf3 = np.zeros(len(data))\n",
    "\n",
    "for n in range(0, len(data)):\n",
    "    count_day[n] = delay_dict[origin_vals[n]][date_vals[n]][\"total\"]\n",
    "    delay_day[n] = np.average(delay_dict[origin_vals[n]][date_vals[n]][\"train\"])\n",
    "    delay_month[n] = np.average(delay_dict_month[origin_vals[n]][month_vals[n]][\"train\"])\n",
    "    delay_tf1[n] = np.average(delay_dict_tf1[origin_vals[n]][delay_tf1[n]][\"train\"])\n",
    "    delay_tf2[n] = np.average(delay_dict_tf2[origin_vals[n]][delay_tf2[n]][\"train\"])\n",
    "    delay_tf3[n] = np.average(delay_dict_tf3[origin_vals[n]][delay_tf3[n]][\"train\"])\n",
    "    \n",
    "data[\"count_day\"] = count_day\n",
    "data[\"delay_day\"] = delay_day\n",
    "data[\"delay_month\"] = delay_month\n",
    "data[\"delay_tf1\"] = delay_tf1\n",
    "data[\"delay_tf2\"] = delay_tf2\n",
    "data[\"delay_tf3\"] = delay_tf3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"origin\"] = pd.Categorical(data[\"origin\"])\n",
    "data[\"dest\"] = pd.Categorical(data[\"dest\"])\n",
    "data[\"carrier\"] = pd.Categorical(data[\"carrier\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data[\"is_test\"] == 0]\n",
    "test = data[data[\"is_test\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168573 168203\n"
     ]
    }
   ],
   "source": [
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_features = [\"distance\", \n",
    "                \"origin\", \n",
    "                \"dest\", \n",
    "                \"carrier\", \n",
    "                \"sched_arr_hr\", \n",
    "                \"sched_dep_hr\", \n",
    "                \"precip\", \n",
    "                \"temp\", \n",
    "                \"humid\", \n",
    "                \"wind_speed\", \n",
    "                \"count_day\", \n",
    "                \"delay_day\",\n",
    "                \"delay_month\",\n",
    "                \"delay_tf1\",\n",
    "                \"delay_tf2\",\n",
    "                \"delay_tf3\",\n",
    "                \"visib\",\n",
    "                \"time_feature\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary_logloss', 'auc'},\n",
    "    'num_leaves': 100,\n",
    "    'max_depth': 10,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.7,\n",
    "    'bagging_fraction': 0.7,\n",
    "    'verbose': -1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/falkvandermeirsch/Documents/DSR/env/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train[\"is_val\"] = np.random.randint(low=0, high=9, size=len(train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\tvalid_0's auc: 0.768598\tvalid_0's binary_logloss: 0.564852\n",
      "[100]\tvalid_0's auc: 0.776163\tvalid_0's binary_logloss: 0.553756\n",
      "[150]\tvalid_0's auc: 0.780456\tvalid_0's binary_logloss: 0.549076\n",
      "[200]\tvalid_0's auc: 0.783426\tvalid_0's binary_logloss: 0.546106\n",
      "[250]\tvalid_0's auc: 0.785147\tvalid_0's binary_logloss: 0.544312\n",
      "[300]\tvalid_0's auc: 0.786205\tvalid_0's binary_logloss: 0.543244\n",
      "[350]\tvalid_0's auc: 0.788137\tvalid_0's binary_logloss: 0.54135\n",
      "[400]\tvalid_0's auc: 0.789061\tvalid_0's binary_logloss: 0.540448\n",
      "[450]\tvalid_0's auc: 0.790091\tvalid_0's binary_logloss: 0.539428\n",
      "[500]\tvalid_0's auc: 0.790914\tvalid_0's binary_logloss: 0.538608\n",
      "[550]\tvalid_0's auc: 0.792061\tvalid_0's binary_logloss: 0.537472\n",
      "[600]\tvalid_0's auc: 0.792749\tvalid_0's binary_logloss: 0.536788\n",
      "[650]\tvalid_0's auc: 0.793261\tvalid_0's binary_logloss: 0.536206\n",
      "[700]\tvalid_0's auc: 0.79372\tvalid_0's binary_logloss: 0.535784\n",
      "[750]\tvalid_0's auc: 0.793956\tvalid_0's binary_logloss: 0.53554\n",
      "[800]\tvalid_0's auc: 0.794369\tvalid_0's binary_logloss: 0.535193\n",
      "[850]\tvalid_0's auc: 0.794555\tvalid_0's binary_logloss: 0.535069\n",
      "[900]\tvalid_0's auc: 0.794684\tvalid_0's binary_logloss: 0.535012\n",
      "[950]\tvalid_0's auc: 0.794703\tvalid_0's binary_logloss: 0.535009\n",
      "[1000]\tvalid_0's auc: 0.794938\tvalid_0's binary_logloss: 0.534855\n",
      "[1050]\tvalid_0's auc: 0.795286\tvalid_0's binary_logloss: 0.534613\n",
      "[1100]\tvalid_0's auc: 0.795416\tvalid_0's binary_logloss: 0.534537\n",
      "[1150]\tvalid_0's auc: 0.795626\tvalid_0's binary_logloss: 0.53447\n",
      "[1200]\tvalid_0's auc: 0.795671\tvalid_0's binary_logloss: 0.534569\n",
      "[1250]\tvalid_0's auc: 0.795709\tvalid_0's binary_logloss: 0.534689\n",
      "Early stopping, best iteration is:\n",
      "[1154]\tvalid_0's auc: 0.7957\tvalid_0's binary_logloss: 0.534403\n"
     ]
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(\n",
    "    train[use_features].loc[train[\"is_val\"]>1], \n",
    "    train[\"is_delayed\"].loc[train[\"is_val\"]>1])\n",
    "lgb_eval = lgb.Dataset(\n",
    "    train[use_features].loc[train[\"is_val\"]<=1], \n",
    "    train[\"is_delayed\"].loc[train[\"is_val\"]<=1])\n",
    "gbm = lgb.train(\n",
    "    params, \n",
    "    lgb_train, \n",
    "    num_boost_round=5_000, \n",
    "    valid_sets=lgb_eval, early_stopping_rounds=100, verbose_eval=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred4 = gbm.predict(test[use_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/falkvandermeirsch/Documents/DSR/env/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test[\"is_delayed\"] = 0.2*pred + 0.2*pred2 + 0.2*pred3 + 0.4*pred4\n",
    "test[[\"id\" ,\"is_delayed\"]].to_csv(\"sub14.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

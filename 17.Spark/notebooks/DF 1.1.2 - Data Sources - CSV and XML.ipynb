{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "sc = pyspark.SparkContext('local[*]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!rm ./metastore_db/*.lck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sqlc = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/databricks/spark-csv/raw/master/src/test/resources/cars.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cars = sqlc.read.format(\"com.databricks.spark.csv\") \\\n",
    "                .option(\"header\", \"true\") \\\n",
    "                .option(\"inferSchema\", \"true\") \\\n",
    "                .load(\"cars.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_cars.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_cars.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "customSchema = StructType([StructField(\"year\", StringType(), True),\n",
    "                           StructField(\"make\", StringType(), True),\n",
    "                           StructField(\"model\", StringType(), True), \n",
    "                           StructField(\"comment\", StringType(), True),\n",
    "                           StructField(\"blank\", StringType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cars2 = sqlc.read.load(path=\"cars.csv\", \n",
    "                          format=\"com.databricks.spark.csv\", \n",
    "                          schema=customSchema,\n",
    "                          header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_cars2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -rf newcars.csv\n",
    "\n",
    "selectedData = df_cars.select(\"year\", \"model\",\"comment\")\n",
    "selectedData.coalesce(1).write.format(\"com.databricks.spark.csv\") \\\n",
    "                        .option(\"header\", \"true\") \\\n",
    "                        .option(\"nullValue\",\"NA\") \\\n",
    "                        .save(\"newcars.csv\") \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls -l newcars.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -rf newcars.csv.gz\n",
    "selectedData.write.format(\"com.databricks.spark.csv\") \\\n",
    "                    .option(\"header\", \"true\") \\\n",
    "                    .option(\"codec\", \"gzip\") \\\n",
    "                    .save(\"newcars.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls -l newcars.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/databricks/spark-xml/raw/master/src/test/resources/books.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!cat books.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_books = sqlc.read.format(\"com.databricks.spark.xml\") \\\n",
    "                    .option(\"rowTag\", \"book\") \\\n",
    "                    .load(\"books.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_books.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_books.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -rf newbooks.xml\n",
    "\n",
    "selectedData = df_books.select(\"author\", \"_id\")\n",
    "selectedData.write.format(\"com.databricks.spark.xml\") \\\n",
    "                .option(\"rootTag\", \"books\") \\\n",
    "                .option(\"rowTag\", \"book\") \\\n",
    "                .save(\"newbooks.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType\n",
    "\n",
    "customSchema = StructType([StructField(\"_id\", StringType(), nullable = True), \n",
    "                           StructField(\"author\", StringType(), nullable = True),\n",
    "                           StructField(\"description\", StringType(), nullable = True),\n",
    "                           StructField(\"genre\", StringType(),nullable = True), \n",
    "                           StructField(\"price\", DoubleType(), nullable = True),\n",
    "                           StructField(\"publish_date\", StringType(), nullable = True),\n",
    "                           StructField(\"title\", StringType(), nullable = True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_books = sqlc.read.format(\"com.databricks.spark.xml\") \\\n",
    "                    .option(\"rowTag\", \"book\") \\\n",
    "                    .schema(customSchema) \\\n",
    "                    .load(\"books.xml\")\n",
    "            \n",
    "selectedData = df_books.select(\"author\", \"_id\")\n",
    "selectedData.write.format(\"com.databricks.spark.xml\") \\\n",
    "                .option(\"rootTag\", \"books\") \\\n",
    "                .option(\"rowTag\", \"book\") \\\n",
    "                .mode(\"overwrite\") \\\n",
    "                .save(\"newbooks.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
